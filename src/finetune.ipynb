{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Update venv\\Lib\\site-packages\\llama_index\\finetuning\\embeddings\\common.py\n",
    "def generate_qa_embedding_pairs\n",
    "    ...\n",
    "    save_counter = start_index\n",
    "\n",
    "    # added --------------------------------------------------------------\n",
    "    import time\n",
    "    counter, start_time = 0, time.time()\n",
    "    # --------------------------------------------------------------------\n",
    "\n",
    "    for node_id, text in tqdm(\n",
    "        list(node_dict.items())[start_index:], initial=start_index\n",
    "    ):\n",
    "        \n",
    "        # added --------------------------------------------------------------\n",
    "        counter += 1\n",
    "        if counter > 10 and time.time() - start_time < 60:\n",
    "            time.sleep(60 - (time.time() - start_time))\n",
    "            counter, start_time = 0, time.time()\n",
    "        # --------------------------------------------------------------------\n",
    "\n",
    "        query = qa_generate_prompt_tmpl.format(\n",
    "            context_str=text, num_questions_per_chunk=num_questions_per_chunk\n",
    "        )\n",
    "    ...\n",
    "''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "x:\\Work\\Risk-Embedding-Model\\venv\\lib\\site-packages\\pydantic\\_internal\\_fields.py:132: UserWarning: Field \"model_id\" in DeployedModel has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "x:\\Work\\Risk-Embedding-Model\\venv\\lib\\site-packages\\pydantic\\_internal\\_fields.py:132: UserWarning: Field \"model_name\" in HuggingFaceLLM has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "x:\\Work\\Risk-Embedding-Model\\venv\\lib\\site-packages\\pydantic\\_internal\\_fields.py:132: UserWarning: Field \"model_kwargs\" in HuggingFaceLLM has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "x:\\Work\\Risk-Embedding-Model\\venv\\lib\\site-packages\\pydantic\\_internal\\_fields.py:132: UserWarning: Field \"model_name\" in HuggingFaceInferenceAPI has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "x:\\Work\\Risk-Embedding-Model\\venv\\lib\\site-packages\\pydantic\\_internal\\_fields.py:132: UserWarning: Field \"model_name\" in TextGenerationInference has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "import pickle\n",
    "import openparse\n",
    "from tqdm import tqdm\n",
    "from huggingface_hub import login\n",
    "import google.generativeai as genai\n",
    "from llama_index.core import Settings\n",
    "from llama_index.llms.gemini import Gemini\n",
    "from transformers import BitsAndBytesConfig\n",
    "from llama_index.llms.huggingface import HuggingFaceLLM\n",
    "from llama_index.finetuning import generate_qa_embedding_pairs\n",
    "from llama_index.core.llms.chatml_utils import messages_to_prompt, completion_to_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "HF_CACHE_DIR = \"../models/hf\"\n",
    "os.environ['HF_HOME'] = HF_CACHE_DIR\n",
    "\n",
    "TIKTOKEN_CACHE_DIR = \"../models/tiktoken\"\n",
    "os.environ[\"TIKTOKEN_CACHE_DIR\"] = TIKTOKEN_CACHE_DIR\n",
    "# assert os.path.exists(os.path.join(TIKTOKEN_CACHE_DIR, \"9b5ad71b2ce5302211f9c61530b329a4922fc6a4\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read API tokens (SHOULD BE CREATED BY USER)\n",
    "with open('../reqs/tokens.json', 'r') as file:\n",
    "    tokens = json.load(file)\n",
    "\n",
    "HF_ACCESS_TOKEN = tokens['HF_ACCESS_TOKEN'][0]\n",
    "GOOGLE_API_KEY = tokens['GOOGLE_API_KEY'][0]\n",
    "\n",
    "login(token=HF_ACCESS_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set/Load LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API model\n",
    "llm = Gemini(\n",
    "    api_key = GOOGLE_API_KEY,\n",
    "    model = \"models/gemini-1.0-pro\",\n",
    "    temperature = 0.3,\n",
    ")\n",
    "Settings.llm = llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Local model\n",
    "# llm_name = \"meta-llama/Llama-3.2-3B\"\n",
    "\n",
    "# quantization_config = BitsAndBytesConfig(\n",
    "#     load_in_4bit = True,\n",
    "#     bnb_4bit_compute_dtype = torch.float16,\n",
    "#     bnb_4bit_quant_type = \"nf4\",\n",
    "#     bnb_4bit_use_double_quant = True,\n",
    "# )\n",
    "\n",
    "# llm = HuggingFaceLLM(\n",
    "#     model_name = llm_name,\n",
    "#     tokenizer_name = llm_name,\n",
    "#     context_window = 2048,\n",
    "#     max_new_tokens = 512,\n",
    "\n",
    "#     generate_kwargs = {\n",
    "#         \"do_sample\": True,\n",
    "#         \"temperature\": 0.5,\n",
    "#     },\n",
    "#     model_kwargs = {\n",
    "#         # \"torch_dtype\": torch.float16,\n",
    "#         \"quantization_config\": quantization_config,\n",
    "#         \"cache_dir\": HF_CACHE_DIR,\n",
    "#     },\n",
    "#     device_map = \"auto\",\n",
    "#     is_chat_model = True,\n",
    "\n",
    "#     completion_to_prompt = completion_to_prompt,\n",
    "#     messages_to_prompt = messages_to_prompt,\n",
    "# )\n",
    "\n",
    "# Settings.llm = llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_folders = 5\n",
    "train_files = []\n",
    "\n",
    "for i in range(num_train_folders):\n",
    "    train_files.append(glob.glob(f\"../data/finetune/docs/train_{i+1}/*.pdf\"))\n",
    "\n",
    "val_files = glob.glob(\"../data/finetune/docs/val/*.pdf\")\n",
    "\n",
    "train_files, val_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_corpus(files):\n",
    "    parser = openparse.DocumentParser(\n",
    "        table_args = {\"parsing_algorithm\": \"pymupdf\",},\n",
    "    )\n",
    "\n",
    "    nodes = []\n",
    "    for file in tqdm(files):\n",
    "        try:\n",
    "            nodes += parser.parse(file, ocr=True).to_llama_index_nodes()\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "    return nodes\n",
    "\n",
    "# Parse and save\n",
    "for i in range(num_train_folders):\n",
    "    train_nodes = parse_corpus(train_files[i])\n",
    "    with open(f'../data/finetune/docs/train_{i+1}/nodes.pkl', 'wb') as file: pickle.dump(train_nodes, file)\n",
    "    print(len(train_nodes))\n",
    "    \n",
    "val_nodes = parse_corpus(val_files)\n",
    "with open('../data/finetune/docs/val/nodes.pkl', 'wb') as file: pickle.dump(val_nodes, file) \n",
    "print(len(val_nodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_train_folders):\n",
    "    if i + 1 == 1:\n",
    "        with open(f'../data/finetune/docs/train_{i+1}/nodes.pkl', 'rb') as file:\n",
    "            train_nodes = pickle.load(file)\n",
    "\n",
    "        train_dataset = generate_qa_embedding_pairs(\n",
    "            llm = llm,\n",
    "            nodes = train_nodes,\n",
    "            num_questions_per_chunk = 2,\n",
    "            output_path = f\"../data/finetune/datasets/train_{i+1}.json\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = generate_qa_embedding_pairs(\n",
    "    llm = llm,\n",
    "    nodes = val_nodes,\n",
    "    num_questions_per_chunk = 2,\n",
    "    output_path = f\"../data/finetune/datasets/val.json\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_queries = (\"**Question 1:**\",)\n",
    "\n",
    "\n",
    "# Combine train sets\n",
    "json_files = glob.glob(\"../data/finetune/datasets/train_*.json\")\n",
    "train_sets = []\n",
    "\n",
    "for f in json_files:\n",
    "    with open(f, 'r') as file:\n",
    "        train_sets.append(json.load(file))\n",
    "\n",
    "queries_size = []\n",
    "corpus_size = []\n",
    "relevant_docs_size = []\n",
    "\n",
    "for train_set in train_sets:\n",
    "    queries_size.append(len(train_set['queries'].keys()))\n",
    "    corpus_size.append(len(train_set['corpus'].keys()))\n",
    "    relevant_docs_size.append(len(train_set['relevant_docs'].keys()))\n",
    "\n",
    "train_set = {}\n",
    "for t in train_sets:\n",
    "    for key1 in t:\n",
    "        for key2 in t[key1]:\n",
    "            if key1 == 'mode':\n",
    "                continue\n",
    "            if key1 not in train_set.keys():\n",
    "                train_set[key1] = {}\n",
    "            train_set[key1][key2] = t[key1][key2]\n",
    "\n",
    "train_set[\"mode\"] = \"text\"\n",
    "\n",
    "assert sum(queries_size) == len(train_set['queries'].keys()), \"Unmatched number of queries\"\n",
    "assert sum(corpus_size) == len(train_set['corpus'].keys()), \"Unmatched number of corpus\"\n",
    "assert sum(relevant_docs_size) == len(train_set['relevant_docs'].keys()), \"Unmatched number of relevant_docs\"\n",
    "\n",
    "# Remove bad questions\n",
    "train_set['queries'] = {key:val for key, val in train_set['queries'].items() if val not in bad_queries}\n",
    "\n",
    "with open(\"../data/finetune/datasets/train.json\", 'w') as f:\n",
    "    json.dump(train_set, f)\n",
    "\n",
    "\n",
    "# Remove bad queries\n",
    "with open(\"../data/finetune/datasets/val.json\", 'r') as file:\n",
    "    val_dataset = json.load(file)\n",
    "\n",
    "val_dataset['queries'] = {key:val for key, val in val_dataset['queries'].items() if val not in bad_queries}\n",
    "\n",
    "with open(\"../data/finetune/datasets/val.json\", 'w') as f:\n",
    "    json.dump(val_dataset, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetune Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from sentence_transformers import SentenceTransformer, losses\n",
    "from llama_index.core.evaluation import EmbeddingQAFinetuneDataset\n",
    "from llama_index.finetuning import SentenceTransformersFinetuneEngine\n",
    "from sentence_transformers.evaluation import InformationRetrievalEvaluator\n",
    "\n",
    "\n",
    "stransformers_cache_dir = \"../models/stransformers\"\n",
    "os.environ[\"SENTENCE_TRANSFORMERS_HOME\"] = stransformers_cache_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = EmbeddingQAFinetuneDataset.from_json(\"../data/finetune/datasets/train.json\")\n",
    "val_dataset = EmbeddingQAFinetuneDataset.from_json(\"../data/finetune/datasets/val.json\")\n",
    "models = [\n",
    "    \"Snowflake/snowflake-arctic-embed-m\",\n",
    "    \"Snowflake/snowflake-arctic-embed-l\",\n",
    "    \"dunzhang/stella_en_400M_v5l\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_index = 1\n",
    "num_times = 1\n",
    "epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, num_times + 1):\n",
    "    model_id = \\\n",
    "        models[model_index-1] if i == 1 else \\\n",
    "        f\"../models/stransformers/{models[model_index-1].split('/')[-1]}-finetuned-{(i-1)*epochs}\"\n",
    "\n",
    "    # model = SentenceTransformer(embedding_name, trust_remote_code=True)\n",
    "    # loss = losses.MultipleNegativesRankingLoss(model)\n",
    "    # loss = losses.MatryoshkaLoss(model, loss, [768, 256])  # for m\n",
    "    # loss = losses.MatryoshkaLoss(model, loss, [1024, 512])  # for l\n",
    "\n",
    "    finetune_engine = SentenceTransformersFinetuneEngine(\n",
    "        dataset = train_dataset,\n",
    "        model_id = model_id,\n",
    "        model_output_path = \\\n",
    "            f\"../models/stransformers/{model_id.split('/')[-1]}-finetuned-{i*epochs}\" if i == 1 else \\\n",
    "            f\"../models/stransformers/{model_id.split('/')[-1].replace(str((i-1)*epochs), str(i*epochs))}\",\n",
    "        val_dataset = val_dataset,\n",
    "        epochs = epochs,\n",
    "        trust_remote_code = True,\n",
    "        batch_size = 12 if model_index == 1 else 2,\n",
    "        evaluation_steps = 100 if model_index == 1 else 200,\n",
    "        # loss = loss,\n",
    "    )\n",
    "\n",
    "    finetune_engine.finetune()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model_id, dataset, name, output_path):\n",
    "    Path(output_path).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    corpus = dataset.corpus\n",
    "    queries = dataset.queries\n",
    "    relevant_docs = dataset.relevant_docs\n",
    "    evaluator = InformationRetrievalEvaluator(\n",
    "        queries, corpus, relevant_docs, name=name,\n",
    "    )\n",
    "\n",
    "    model = SentenceTransformer(model_id)\n",
    "\n",
    "    return evaluator(model, output_path=output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for i in range(1, num_times + 1):\n",
    "    if i == 1:\n",
    "        model_base = models[model_index-1]\n",
    "        output_path = f\"../results/{model_base.split('/')[-1]}\"\n",
    "        results['base'] = evaluate(model_base, val_dataset, \"base\", output_path)\n",
    "    else:\n",
    "        output_path = f\"../results/{model_base.split('/')[-1]}\"\n",
    "\n",
    "    model_finetuned = f\"../models/stransformers/{models[model_index-1].split('/')[-1]}-finetuned-{i*epochs}\"\n",
    "    results[f\"finetuned-{i*epochs}\"] = evaluate(\n",
    "        model_finetuned,\n",
    "        val_dataset,\n",
    "        f\"finetuned-{i*epochs}\",\n",
    "        output_path,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0.40312160993233853 0.7864231160513896\n",
      "Improvement: 95%\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, num_times + 1):\n",
    "    results_base = results['base']\n",
    "    results_finetuned = results[f\"finetuned-{i*epochs}\"]\n",
    "\n",
    "    improvement = round((results_finetuned - results_base) / results_base * 100)\n",
    "    print(i)\n",
    "    print(results_base, results_finetuned)\n",
    "    print(f\"Improvement: {improvement}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
